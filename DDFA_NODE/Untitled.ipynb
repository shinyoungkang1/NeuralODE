{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbdf8eed-f17a-4b9c-9a2d-1aea49c5e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--adjoint', type=eval, default=False)\n",
    "# parser.add_argument('--visualize', type=eval, default=True)\n",
    "# parser.add_argument('--niters', type=int, default=2000)\n",
    "# parser.add_argument('--lr', type=float, default=0.01)\n",
    "# parser.add_argument('--gpu', type=int, default=0)\n",
    "# parser.add_argument('--train_dir', type=str, default='latent')\n",
    "# args = parser.parse_args()\n",
    "train_dir = 'latent'\n",
    "adjoint = True\n",
    "visualize = True\n",
    "niters = 2000\n",
    "lr = 0.01\n",
    "\n",
    "\n",
    "from tfdiffeq import odeint, move_to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074de5f7-9fd4-4ade-b583-7a4f0622f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spiral2d(nspiral=1000,\n",
    "                      ntotal=500,\n",
    "                      nsample=100,\n",
    "                      start=0.,\n",
    "                      stop=1,  # approximately equal to 6pi\n",
    "                      noise_std=.1,\n",
    "                      a=0.,\n",
    "                      b=1.,\n",
    "                      savefig=True):\n",
    "    \"\"\"Parametric formula for 2d spiral is `r = a + b * theta`.\n",
    "\n",
    "    Args:\n",
    "      nspiral: number of spirals, i.e. batch dimension\n",
    "      ntotal: total number of datapoints per spiral\n",
    "      nsample: number of sampled datapoints for model fitting per spiral\n",
    "      start: spiral starting theta value\n",
    "      stop: spiral ending theta value\n",
    "      noise_std: observation noise standard deviation\n",
    "      a, b: parameters of the Archimedean spiral\n",
    "      savefig: plot the ground truth for sanity check\n",
    "\n",
    "    Returns:\n",
    "      Tuple where first element is true trajectory of size (nspiral, ntotal, 2),\n",
    "      second element is noisy observations of size (nspiral, nsample, 2),\n",
    "      third element is timestamps of size (ntotal,),\n",
    "      and fourth element is timestamps of size (nsample,)\n",
    "    \"\"\"\n",
    "\n",
    "    # add 1 all timestamps to avoid division by 0\n",
    "    orig_ts = np.linspace(start, stop, num=ntotal)\n",
    "    samp_ts = orig_ts[:nsample]\n",
    "\n",
    "    # generate clock-wise and counter clock-wise spirals in observation space\n",
    "    # with two sets of time-invariant latent dynamics\n",
    "    zs_cw = stop + 1. - orig_ts\n",
    "    rs_cw = a + b * 50. / zs_cw\n",
    "    xs, ys = rs_cw * np.cos(zs_cw) - 5., rs_cw * np.sin(zs_cw)\n",
    "    orig_traj_cw = np.stack((xs, ys), axis=1)\n",
    "\n",
    "    zs_cc = orig_ts\n",
    "    rw_cc = a + b * zs_cc\n",
    "    xs, ys = rw_cc * np.cos(zs_cc) + 5., rw_cc * np.sin(zs_cc)\n",
    "    orig_traj_cc = np.stack((xs, ys), axis=1)\n",
    "\n",
    "    if savefig:\n",
    "        plt.figure()\n",
    "        plt.plot(orig_traj_cw[:, 0], orig_traj_cw[:, 1], label='clock')\n",
    "        plt.plot(orig_traj_cc[:, 0], orig_traj_cc[:, 1], label='counter clock')\n",
    "        plt.legend()\n",
    "        plt.savefig('./ground_truth.png', dpi=500)\n",
    "        print('Saved ground truth spiral at {}'.format('./ground_truth.png'))\n",
    "\n",
    "    # sample starting timestamps\n",
    "    orig_trajs = []\n",
    "    samp_trajs = []\n",
    "    for _ in range(nspiral):\n",
    "        # don't sample t0 very near the start or the end\n",
    "        t0_idx = npr.multinomial(\n",
    "            1, [1. / (ntotal - 2. * nsample)] * (ntotal - int(2 * nsample)))\n",
    "        t0_idx = np.argmax(t0_idx) + nsample\n",
    "\n",
    "        cc = bool(npr.rand() > .5)  # uniformly select rotation\n",
    "        orig_traj = orig_traj_cc if cc else orig_traj_cw\n",
    "        orig_trajs.append(orig_traj)\n",
    "\n",
    "        samp_traj = orig_traj[t0_idx:t0_idx + nsample, :].copy()\n",
    "        samp_traj += npr.randn(*samp_traj.shape) * noise_std\n",
    "        samp_trajs.append(samp_traj)\n",
    "\n",
    "    # batching for sample trajectories is good for RNN; batching for original\n",
    "    # trajectories only for ease of indexing\n",
    "    orig_trajs = np.stack(orig_trajs, axis=0)\n",
    "    samp_trajs = np.stack(samp_trajs, axis=0)\n",
    "\n",
    "    return orig_trajs, samp_trajs, orig_ts, samp_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6ed051-b502-46a0-bdff-69bde76fcbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentODEfunc(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim=4, nhidden=20):\n",
    "        super(LatentODEfunc, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(nhidden, activation='elu')\n",
    "        self.fc2 = tf.keras.layers.Dense(nhidden, activation='elu')\n",
    "        self.fc3 = tf.keras.layers.Dense(latent_dim)\n",
    "        self.nfe = 0\n",
    "\n",
    "    def call(self, t, x):\n",
    "        self.nfe += 1\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RecognitionRNN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=25, nbatch=1):\n",
    "        super(RecognitionRNN, self).__init__()\n",
    "        self.nhidden = nhidden\n",
    "        self.nbatch = nbatch\n",
    "        self.i2h = tf.keras.layers.Dense(nhidden, activation='tanh')\n",
    "        self.h2o = tf.keras.layers.Dense(latent_dim * 2)\n",
    "\n",
    "    def call(self, x, h):\n",
    "        combined = tf.concat((x, h), axis=1)\n",
    "        h = self.i2h(combined)\n",
    "        out = self.h2o(h)\n",
    "        return out, h\n",
    "\n",
    "    def initHidden(self):\n",
    "        return tf.zeros([self.nbatch, self.nhidden], dtype=tf.float64)\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(nhidden, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(obs_dim)\n",
    "\n",
    "    def call(self, z):\n",
    "        out = self.fc1(z)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RunningAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val\n",
    "\n",
    "\n",
    "def log_normal_pdf(x, mean, logvar):\n",
    "    const = tf.convert_to_tensor(np.array([2. * np.pi]), dtype=tf.float64)\n",
    "    const = move_to_device(const, device)\n",
    "    const = tf.compat.v1.log(const)\n",
    "    return -.5 * (const + logvar + (x - mean) ** 2. / tf.exp(logvar))\n",
    "\n",
    "\n",
    "def normal_kl(mu1, lv1, mu2, lv2):\n",
    "    v1 = tf.exp(lv1)\n",
    "    v2 = tf.exp(lv2)\n",
    "    lstd1 = lv1 / 2.\n",
    "    lstd2 = lv2 / 2.\n",
    "\n",
    "    kl = lstd2 - lstd1 + ((v1 + (mu1 - mu2) ** 2.) / (2. * v2)) - .5\n",
    "    return kl\n",
    "\n",
    "\n",
    "def save_states(orig_ts, orig_trajs, samp_ts, samp_trajs):\n",
    "    ots = orig_ts.numpy()\n",
    "    otjs = orig_trajs.numpy()\n",
    "    sts = samp_ts.numpy()\n",
    "    stjs = samp_trajs.numpy()\n",
    "\n",
    "    orig_ts_path = os.path.join(train_dir, 'orig_ts')\n",
    "    orig_trajs_path = os.path.join(train_dir, 'orig_trajs')\n",
    "    samp_ts_path = os.path.join(train_dir, 'samp_ts')\n",
    "    samp_trajs_path = os.path.join(train_dir, 'samp_trajs')\n",
    "\n",
    "    np.save(orig_ts_path, ots)\n",
    "    np.save(orig_trajs_path, otjs)\n",
    "    np.save(samp_ts_path, sts)\n",
    "    np.save(samp_trajs_path, stjs)\n",
    "\n",
    "\n",
    "def restore_states():\n",
    "    orig_ts_path = os.path.join(train_dir, 'orig_ts.npy')\n",
    "    orig_trajs_path = os.path.join(train_dir, 'orig_trajs.npy')\n",
    "    samp_ts_path = os.path.join(train_dir, 'samp_ts.npy')\n",
    "    samp_trajs_path = os.path.join(train_dir, 'samp_trajs.npy')\n",
    "\n",
    "    ots = tf.convert_to_tensor(np.load(orig_ts_path), dtype=tf.float64)\n",
    "    otjs = tf.convert_to_tensor(np.load(orig_trajs_path), dtype=tf.float32)\n",
    "    sts = tf.convert_to_tensor(np.load(samp_ts_path), dtype=tf.float32)\n",
    "    stjs = tf.convert_to_tensor(np.load(samp_trajs_path), dtype=tf.float32)\n",
    "\n",
    "    states = dict(orig_ts=ots, orig_trajs=otjs,\n",
    "                  samp_ts=sts, samp_trajs=stjs)\n",
    "\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "321b0698-b69f-4335-80d4-5ed817737168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 20:33:06.645518: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 20:33:06.645628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 20:33:06.645670: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 20:33:06.645735: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 20:33:06.645776: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-22 20:33:06.645811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 9994 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ground truth spiral at ./ground_truth.png\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B170.140.242.213/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m noise_std_ \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mzeros(pred_x\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64) \u001b[39m+\u001b[39m noise_std\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B170.140.242.213/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m noise_logvar \u001b[39m=\u001b[39m \u001b[39m2.\u001b[39m \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mlog(noise_std_)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B170.140.242.213/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m logpx \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_sum(log_normal_pdf(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B170.140.242.213/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m     samp_trajs, pred_x, noise_logvar), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B170.140.242.213/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m logpx \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_sum(logpx, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B170.140.242.213/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m pz0_mean \u001b[39m=\u001b[39m pz0_logvar \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mzeros(z0\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64)\n",
      "\u001b[1;32m/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B170.140.242.213/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m const \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(np\u001b[39m.\u001b[39marray([\u001b[39m2.\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mpi]), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B170.140.242.213/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m const \u001b[39m=\u001b[39m move_to_device(const, device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B170.140.242.213/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m const \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mlog(const)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B170.140.242.213/home/michael/Synology/Desktop/Data/Python/Gait-Signatures/NeuralODE/DDFA_NODE/Untitled.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m.5\u001b[39m \u001b[39m*\u001b[39m (const \u001b[39m+\u001b[39m logvar \u001b[39m+\u001b[39m (x \u001b[39m-\u001b[39m mean) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.\u001b[39m \u001b[39m/\u001b[39m tf\u001b[39m.\u001b[39mexp(logvar))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'log'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    latent_dim = 4\n",
    "    nhidden = 20\n",
    "    rnn_nhidden = 25\n",
    "    obs_dim = 2\n",
    "    nspiral = 1000\n",
    "    start = 0.\n",
    "    stop = 6 * np.pi\n",
    "    noise_std = .3\n",
    "    a = 0.\n",
    "    b = .3\n",
    "    ntotal = 1000\n",
    "    nsample = 100\n",
    "    device = 'gpu:0' if tf.test.is_gpu_available() else 'cpu'\n",
    "\n",
    "    with tf.device(device):\n",
    "        # generate toy spiral data\n",
    "        orig_trajs, samp_trajs, orig_ts, samp_ts = generate_spiral2d(\n",
    "            nspiral=nspiral,\n",
    "            start=start,\n",
    "            stop=stop,\n",
    "            noise_std=noise_std,\n",
    "            a=a, b=b\n",
    "        )\n",
    "\n",
    "        orig_ts = tf.convert_to_tensor(orig_ts, dtype=tf.float64)\n",
    "        orig_trajs = tf.convert_to_tensor(orig_trajs, dtype=tf.float64)\n",
    "        samp_trajs = tf.convert_to_tensor(samp_trajs, dtype=tf.float64)\n",
    "        samp_ts = tf.convert_to_tensor(samp_ts, dtype=tf.float64)\n",
    "\n",
    "        # model\n",
    "        func = LatentODEfunc(latent_dim, nhidden)\n",
    "        rec = RecognitionRNN(latent_dim, obs_dim, rnn_nhidden, nspiral)\n",
    "        dec = Decoder(latent_dim, obs_dim, nhidden)\n",
    "        optimizer = tf.keras.optimizers.Adam(lr)\n",
    "        loss_meter = RunningAverageMeter()\n",
    "\n",
    "        saver = tf.train.Checkpoint(func=func, rec=rec, dec=dec, optimizer=optimizer)\n",
    "\n",
    "        if train_dir is not None:\n",
    "            if not os.path.exists(train_dir):\n",
    "                os.makedirs(train_dir)\n",
    "            else:\n",
    "                if tf.compat.v1.train.checkpoint_exists(train_dir):\n",
    "                    path = tf.compat.v1.train.latest_checkpoint(train_dir)\n",
    "\n",
    "                    if path is not None:\n",
    "                        saver.restore(path)\n",
    "\n",
    "                        states = restore_states()\n",
    "                        orig_trajs = states['orig_trajs']\n",
    "                        samp_trajs = states['samp_trajs']\n",
    "                        orig_ts = states['orig_ts']\n",
    "                        samp_ts = states['samp_ts']\n",
    "                        print('Loaded ckpt from {}'.format(path))\n",
    "\n",
    "        for itr in range(1, niters + 1):\n",
    "            # backward in time to infer q(z_0)\n",
    "            with tf.GradientTape() as tape:\n",
    "                h = rec.initHidden()\n",
    "                for t in reversed(range(samp_trajs.shape[1])):\n",
    "                    obs = samp_trajs[:, t, :]\n",
    "                    out, h = rec(obs, h)\n",
    "                qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "                epsilon = tf.convert_to_tensor(np.random.randn(*qz0_mean.shape.as_list()), dtype=qz0_mean.dtype)\n",
    "                z0 = epsilon * tf.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "                # forward in time and solve ode for reconstructions\n",
    "                pred_z = tf.transpose(odeint(func, z0, samp_ts), [1, 0, 2])\n",
    "                pred_x = dec(pred_z)\n",
    "\n",
    "                # compute loss\n",
    "                noise_std_ = tf.zeros(pred_x.shape, dtype=tf.float64) + noise_std\n",
    "                noise_logvar = 2. * tf.compat.v1.log(noise_std_)\n",
    "                logpx = tf.reduce_sum(log_normal_pdf(\n",
    "                    samp_trajs, pred_x, noise_logvar), axis=-1)\n",
    "                logpx = tf.reduce_sum(logpx, axis=-1)\n",
    "                pz0_mean = pz0_logvar = tf.zeros(z0.shape, dtype=tf.float64)\n",
    "                analytic_kl = tf.reduce_sum(normal_kl(qz0_mean, qz0_logvar,\n",
    "                                                      pz0_mean, pz0_logvar), axis=-1)\n",
    "                loss = tf.reduce_mean(-logpx + analytic_kl, axis=0)\n",
    "\n",
    "            params = (list(func.variables) + list(dec.variables) + list(rec.variables))\n",
    "            grad = tape.gradient(loss, params)\n",
    "            grad_vars = zip(grad, params)\n",
    "\n",
    "            optimizer.apply_gradients(grad_vars)\n",
    "            loss_meter.update(loss.numpy())\n",
    "\n",
    "            print('Iter: {}, running avg elbo: {:.4f}'.format(itr, -loss_meter.avg))\n",
    "\n",
    "            if itr != 0 and (itr + 1) % 100 == 0:\n",
    "                if train_dir is not None:\n",
    "                    ckpt_path = os.path.join(train_dir, 'ckpt')\n",
    "\n",
    "                    saver.save(ckpt_path)\n",
    "                    save_states(orig_ts, orig_trajs, samp_ts, samp_trajs)\n",
    "                    print('Stored ckpt at {}'.format(ckpt_path))\n",
    "\n",
    "        print('Training complete after {} iters.'.format(itr))\n",
    "\n",
    "        if visualize:\n",
    "            # sample from trajectorys' approx. posterior\n",
    "            h = rec.initHidden()\n",
    "            for t in reversed(range(samp_trajs.shape[1])):\n",
    "                obs = samp_trajs[:, t, :]\n",
    "                out, h = rec(obs, h)\n",
    "            qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "            epsilon = tf.convert_to_tensor(np.random.randn(*qz0_mean.shape.as_list()), dtype=tf.float64)\n",
    "            z0 = epsilon * tf.exp(.5 * qz0_logvar) + qz0_mean\n",
    "            orig_ts = tf.convert_to_tensor(orig_ts, dtype=tf.float32)\n",
    "\n",
    "            # take first trajectory for visualization\n",
    "            z0 = z0[0:1]\n",
    "\n",
    "            ts_pos = np.linspace(0., 2. * np.pi, num=2000)\n",
    "            ts_neg = np.linspace(-np.pi, 0., num=2000)[::-1].copy()\n",
    "            ts_pos = tf.convert_to_tensor(ts_pos, dtype=tf.float32)\n",
    "            ts_neg = tf.convert_to_tensor(ts_neg, dtype=tf.float32)\n",
    "\n",
    "            zs_pos = odeint(func, z0, ts_pos)\n",
    "            zs_neg = odeint(func, z0, ts_neg)\n",
    "\n",
    "            xs_pos = dec(zs_pos)\n",
    "            xs_neg = tf.reverse(dec(zs_neg), axis=[0])\n",
    "\n",
    "            xs_pos = xs_pos.numpy().squeeze(1)\n",
    "            xs_neg = xs_neg.numpy().squeeze(1)\n",
    "            orig_traj = orig_trajs[0].numpy()\n",
    "            samp_traj = samp_trajs[0].numpy()\n",
    "\n",
    "            # xs_neg = np.clip(xs_neg, xs_pos.min(), xs_pos.max())\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(orig_traj[:, 0], orig_traj[:, 1],\n",
    "                     'g', label='true trajectory')\n",
    "            plt.plot(xs_pos[:, 0], xs_pos[:, 1], 'r',\n",
    "                     label='learned trajectory (t>0)')\n",
    "            plt.plot(xs_neg[:, 0], xs_neg[:, 1], 'c',\n",
    "                     label='learned trajectory (t<0)')\n",
    "            plt.scatter(samp_traj[:, 0], samp_traj[\n",
    "                        :, 1], label='sampled data', s=3)\n",
    "            plt.legend()\n",
    "            plt.savefig('./vis.png', dpi=500)\n",
    "            print('Saved visualization figure at {}'.format('./vis.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fbc0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdiffeq",
   "language": "python",
   "name": "tfdiffeq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
