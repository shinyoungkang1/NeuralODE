{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbdf8eed-f17a-4b9c-9a2d-1aea49c5e5ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn-paper' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tfdiffeq/lib/python3.10/site-packages/matplotlib/style/core.py:137\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfdiffeq/lib/python3.10/site-packages/matplotlib/__init__.py:866\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[0;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[1;32m    865\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 866\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_or_url(fname) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfdiffeq/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfdiffeq/lib/python3.10/site-packages/matplotlib/__init__.py:843\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    842\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[0;32m--> 843\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn-paper'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     13\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mset_floatx(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# parser = argparse.ArgumentParser()\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# parser.add_argument('--adjoint', type=eval, default=False)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# parser.add_argument('--visualize', type=eval, default=True)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# parser.add_argument('--train_dir', type=str, default='latent')\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# args = parser.parse_args()\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtfdiffeq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m odeint, move_to_device\n",
      "File \u001b[0;32m~/anaconda3/envs/tfdiffeq/lib/python3.10/site-packages/tfdiffeq/__init__.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtfdiffeq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m move_to_device\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Visualization functions\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtfdiffeq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviz_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (plot_phase_portrait,\n\u001b[1;32m     10\u001b[0m                                 plot_vector_field,\n\u001b[1;32m     11\u001b[0m                                 plot_results)\n\u001b[1;32m     14\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124modeint\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124modeint_adjoint\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmove_to_device\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_phase_portrait\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_vector_field\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplot_results\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m            ]\n\u001b[1;32m     19\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.0.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfdiffeq/lib/python3.10/site-packages/tfdiffeq/viz_utils.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseaborn-paper\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_phase_portrait\u001b[39m(func, t0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, xlims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ylims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, num_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      9\u001b[0m                         xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, ip_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    Plots the phase portrait of a system of ODEs containing two dimensions.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m        visualized simultaneously.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfdiffeq/lib/python3.10/site-packages/matplotlib/style/core.py:139\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    137\u001b[0m         style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid package style, path of style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, URL of style file, or library style name (library \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyles are listed in `style.available`)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    143\u001b[0m filtered \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: 'seaborn-paper' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--adjoint', type=eval, default=False)\n",
    "# parser.add_argument('--visualize', type=eval, default=True)\n",
    "# parser.add_argument('--niters', type=int, default=2000)\n",
    "# parser.add_argument('--lr', type=float, default=0.01)\n",
    "# parser.add_argument('--gpu', type=int, default=0)\n",
    "# parser.add_argument('--train_dir', type=str, default='latent')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "from tfdiffeq import odeint, move_to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074de5f7-9fd4-4ade-b583-7a4f0622f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spiral2d(nspiral=1000,\n",
    "                      ntotal=500,\n",
    "                      nsample=100,\n",
    "                      start=0.,\n",
    "                      stop=1,  # approximately equal to 6pi\n",
    "                      noise_std=.1,\n",
    "                      a=0.,\n",
    "                      b=1.,\n",
    "                      savefig=True):\n",
    "    \"\"\"Parametric formula for 2d spiral is `r = a + b * theta`.\n",
    "\n",
    "    Args:\n",
    "      nspiral: number of spirals, i.e. batch dimension\n",
    "      ntotal: total number of datapoints per spiral\n",
    "      nsample: number of sampled datapoints for model fitting per spiral\n",
    "      start: spiral starting theta value\n",
    "      stop: spiral ending theta value\n",
    "      noise_std: observation noise standard deviation\n",
    "      a, b: parameters of the Archimedean spiral\n",
    "      savefig: plot the ground truth for sanity check\n",
    "\n",
    "    Returns:\n",
    "      Tuple where first element is true trajectory of size (nspiral, ntotal, 2),\n",
    "      second element is noisy observations of size (nspiral, nsample, 2),\n",
    "      third element is timestamps of size (ntotal,),\n",
    "      and fourth element is timestamps of size (nsample,)\n",
    "    \"\"\"\n",
    "\n",
    "    # add 1 all timestamps to avoid division by 0\n",
    "    orig_ts = np.linspace(start, stop, num=ntotal)\n",
    "    samp_ts = orig_ts[:nsample]\n",
    "\n",
    "    # generate clock-wise and counter clock-wise spirals in observation space\n",
    "    # with two sets of time-invariant latent dynamics\n",
    "    zs_cw = stop + 1. - orig_ts\n",
    "    rs_cw = a + b * 50. / zs_cw\n",
    "    xs, ys = rs_cw * np.cos(zs_cw) - 5., rs_cw * np.sin(zs_cw)\n",
    "    orig_traj_cw = np.stack((xs, ys), axis=1)\n",
    "\n",
    "    zs_cc = orig_ts\n",
    "    rw_cc = a + b * zs_cc\n",
    "    xs, ys = rw_cc * np.cos(zs_cc) + 5., rw_cc * np.sin(zs_cc)\n",
    "    orig_traj_cc = np.stack((xs, ys), axis=1)\n",
    "\n",
    "    if savefig:\n",
    "        plt.figure()\n",
    "        plt.plot(orig_traj_cw[:, 0], orig_traj_cw[:, 1], label='clock')\n",
    "        plt.plot(orig_traj_cc[:, 0], orig_traj_cc[:, 1], label='counter clock')\n",
    "        plt.legend()\n",
    "        plt.savefig('./ground_truth.png', dpi=500)\n",
    "        print('Saved ground truth spiral at {}'.format('./ground_truth.png'))\n",
    "\n",
    "    # sample starting timestamps\n",
    "    orig_trajs = []\n",
    "    samp_trajs = []\n",
    "    for _ in range(nspiral):\n",
    "        # don't sample t0 very near the start or the end\n",
    "        t0_idx = npr.multinomial(\n",
    "            1, [1. / (ntotal - 2. * nsample)] * (ntotal - int(2 * nsample)))\n",
    "        t0_idx = np.argmax(t0_idx) + nsample\n",
    "\n",
    "        cc = bool(npr.rand() > .5)  # uniformly select rotation\n",
    "        orig_traj = orig_traj_cc if cc else orig_traj_cw\n",
    "        orig_trajs.append(orig_traj)\n",
    "\n",
    "        samp_traj = orig_traj[t0_idx:t0_idx + nsample, :].copy()\n",
    "        samp_traj += npr.randn(*samp_traj.shape) * noise_std\n",
    "        samp_trajs.append(samp_traj)\n",
    "\n",
    "    # batching for sample trajectories is good for RNN; batching for original\n",
    "    # trajectories only for ease of indexing\n",
    "    orig_trajs = np.stack(orig_trajs, axis=0)\n",
    "    samp_trajs = np.stack(samp_trajs, axis=0)\n",
    "\n",
    "    return orig_trajs, samp_trajs, orig_ts, samp_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ed051-b502-46a0-bdff-69bde76fcbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentODEfunc(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim=4, nhidden=20):\n",
    "        super(LatentODEfunc, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(nhidden, activation='elu')\n",
    "        self.fc2 = tf.keras.layers.Dense(nhidden, activation='elu')\n",
    "        self.fc3 = tf.keras.layers.Dense(latent_dim)\n",
    "        self.nfe = 0\n",
    "\n",
    "    def call(self, t, x):\n",
    "        self.nfe += 1\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RecognitionRNN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=25, nbatch=1):\n",
    "        super(RecognitionRNN, self).__init__()\n",
    "        self.nhidden = nhidden\n",
    "        self.nbatch = nbatch\n",
    "        self.i2h = tf.keras.layers.Dense(nhidden, activation='tanh')\n",
    "        self.h2o = tf.keras.layers.Dense(latent_dim * 2)\n",
    "\n",
    "    def call(self, x, h):\n",
    "        combined = tf.concat((x, h), axis=1)\n",
    "        h = self.i2h(combined)\n",
    "        out = self.h2o(h)\n",
    "        return out, h\n",
    "\n",
    "    def initHidden(self):\n",
    "        return tf.zeros([self.nbatch, self.nhidden], dtype=tf.float64)\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(nhidden, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(obs_dim)\n",
    "\n",
    "    def call(self, z):\n",
    "        out = self.fc1(z)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class RunningAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val\n",
    "\n",
    "\n",
    "def log_normal_pdf(x, mean, logvar):\n",
    "    const = tf.convert_to_tensor(np.array([2. * np.pi]), dtype=tf.float64)\n",
    "    const = move_to_device(const, device)\n",
    "    const = tf.log(const)\n",
    "    return -.5 * (const + logvar + (x - mean) ** 2. / tf.exp(logvar))\n",
    "\n",
    "\n",
    "def normal_kl(mu1, lv1, mu2, lv2):\n",
    "    v1 = tf.exp(lv1)\n",
    "    v2 = tf.exp(lv2)\n",
    "    lstd1 = lv1 / 2.\n",
    "    lstd2 = lv2 / 2.\n",
    "\n",
    "    kl = lstd2 - lstd1 + ((v1 + (mu1 - mu2) ** 2.) / (2. * v2)) - .5\n",
    "    return kl\n",
    "\n",
    "\n",
    "def save_states(orig_ts, orig_trajs, samp_ts, samp_trajs):\n",
    "    ots = orig_ts.numpy()\n",
    "    otjs = orig_trajs.numpy()\n",
    "    sts = samp_ts.numpy()\n",
    "    stjs = samp_trajs.numpy()\n",
    "\n",
    "    orig_ts_path = os.path.join(args.train_dir, 'orig_ts')\n",
    "    orig_trajs_path = os.path.join(args.train_dir, 'orig_trajs')\n",
    "    samp_ts_path = os.path.join(args.train_dir, 'samp_ts')\n",
    "    samp_trajs_path = os.path.join(args.train_dir, 'samp_trajs')\n",
    "\n",
    "    np.save(orig_ts_path, ots)\n",
    "    np.save(orig_trajs_path, otjs)\n",
    "    np.save(samp_ts_path, sts)\n",
    "    np.save(samp_trajs_path, stjs)\n",
    "\n",
    "\n",
    "def restore_states():\n",
    "    orig_ts_path = os.path.join(args.train_dir, 'orig_ts.npy')\n",
    "    orig_trajs_path = os.path.join(args.train_dir, 'orig_trajs.npy')\n",
    "    samp_ts_path = os.path.join(args.train_dir, 'samp_ts.npy')\n",
    "    samp_trajs_path = os.path.join(args.train_dir, 'samp_trajs.npy')\n",
    "\n",
    "    ots = tf.convert_to_tensor(np.load(orig_ts_path), dtype=tf.float64)\n",
    "    otjs = tf.convert_to_tensor(np.load(orig_trajs_path), dtype=tf.float32)\n",
    "    sts = tf.convert_to_tensor(np.load(samp_ts_path), dtype=tf.float32)\n",
    "    stjs = tf.convert_to_tensor(np.load(samp_trajs_path), dtype=tf.float32)\n",
    "\n",
    "    states = dict(orig_ts=ots, orig_trajs=otjs,\n",
    "                  samp_ts=sts, samp_trajs=stjs)\n",
    "\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b0698-b69f-4335-80d4-5ed817737168",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    latent_dim = 4\n",
    "    nhidden = 20\n",
    "    rnn_nhidden = 25\n",
    "    obs_dim = 2\n",
    "    nspiral = 1000\n",
    "    start = 0.\n",
    "    stop = 6 * np.pi\n",
    "    noise_std = .3\n",
    "    a = 0.\n",
    "    b = .3\n",
    "    ntotal = 1000\n",
    "    nsample = 100\n",
    "    device = 'gpu:' + str(args.gpu) if tf.test.is_gpu_available() else 'cpu'\n",
    "\n",
    "    with tf.device(device):\n",
    "        # generate toy spiral data\n",
    "        orig_trajs, samp_trajs, orig_ts, samp_ts = generate_spiral2d(\n",
    "            nspiral=nspiral,\n",
    "            start=start,\n",
    "            stop=stop,\n",
    "            noise_std=noise_std,\n",
    "            a=a, b=b\n",
    "        )\n",
    "\n",
    "        orig_ts = tf.convert_to_tensor(orig_ts, dtype=tf.float64)\n",
    "        orig_trajs = tf.convert_to_tensor(orig_trajs, dtype=tf.float64)\n",
    "        samp_trajs = tf.convert_to_tensor(samp_trajs, dtype=tf.float64)\n",
    "        samp_ts = tf.convert_to_tensor(samp_ts, dtype=tf.float64)\n",
    "\n",
    "        # model\n",
    "        func = LatentODEfunc(latent_dim, nhidden)\n",
    "        rec = RecognitionRNN(latent_dim, obs_dim, rnn_nhidden, nspiral)\n",
    "        dec = Decoder(latent_dim, obs_dim, nhidden)\n",
    "        optimizer = tf.train.AdamOptimizer(args.lr)\n",
    "        loss_meter = RunningAverageMeter()\n",
    "\n",
    "        saver = tf.train.Checkpoint(func=func, rec=rec, dec=dec, optimizer=optimizer)\n",
    "\n",
    "        if args.train_dir is not None:\n",
    "            if not os.path.exists(args.train_dir):\n",
    "                os.makedirs(args.train_dir)\n",
    "            else:\n",
    "                if tf.train.checkpoint_exists(args.train_dir):\n",
    "                    path = tf.train.latest_checkpoint(args.train_dir)\n",
    "\n",
    "                    if path is not None:\n",
    "                        saver.restore(path)\n",
    "\n",
    "                        states = restore_states()\n",
    "                        orig_trajs = states['orig_trajs']\n",
    "                        samp_trajs = states['samp_trajs']\n",
    "                        orig_ts = states['orig_ts']\n",
    "                        samp_ts = states['samp_ts']\n",
    "                        print('Loaded ckpt from {}'.format(path))\n",
    "\n",
    "        for itr in range(1, args.niters + 1):\n",
    "            # backward in time to infer q(z_0)\n",
    "            with tf.GradientTape() as tape:\n",
    "                h = rec.initHidden()\n",
    "                for t in reversed(range(samp_trajs.shape[1])):\n",
    "                    obs = samp_trajs[:, t, :]\n",
    "                    out, h = rec(obs, h)\n",
    "                qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "                epsilon = tf.convert_to_tensor(np.random.randn(*qz0_mean.shape.as_list()), dtype=qz0_mean.dtype)\n",
    "                z0 = epsilon * tf.exp(.5 * qz0_logvar) + qz0_mean\n",
    "\n",
    "                # forward in time and solve ode for reconstructions\n",
    "                pred_z = tf.transpose(odeint(func, z0, samp_ts), [1, 0, 2])\n",
    "                pred_x = dec(pred_z)\n",
    "\n",
    "                # compute loss\n",
    "                noise_std_ = tf.zeros(pred_x.shape, dtype=tf.float64) + noise_std\n",
    "                noise_logvar = 2. * tf.log(noise_std_)\n",
    "                logpx = tf.reduce_sum(log_normal_pdf(\n",
    "                    samp_trajs, pred_x, noise_logvar), axis=-1)\n",
    "                logpx = tf.reduce_sum(logpx, axis=-1)\n",
    "                pz0_mean = pz0_logvar = tf.zeros(z0.shape, dtype=tf.float64)\n",
    "                analytic_kl = tf.reduce_sum(normal_kl(qz0_mean, qz0_logvar,\n",
    "                                                      pz0_mean, pz0_logvar), axis=-1)\n",
    "                loss = tf.reduce_mean(-logpx + analytic_kl, axis=0)\n",
    "\n",
    "            params = (list(func.variables) + list(dec.variables) + list(rec.variables))\n",
    "            grad = tape.gradient(loss, params)\n",
    "            grad_vars = zip(grad, params)\n",
    "\n",
    "            optimizer.apply_gradients(grad_vars)\n",
    "            loss_meter.update(loss.numpy())\n",
    "\n",
    "            print('Iter: {}, running avg elbo: {:.4f}'.format(itr, -loss_meter.avg))\n",
    "\n",
    "            if itr != 0 and (itr + 1) % 100 == 0:\n",
    "                if args.train_dir is not None:\n",
    "                    ckpt_path = os.path.join(args.train_dir, 'ckpt')\n",
    "\n",
    "                    saver.save(ckpt_path)\n",
    "                    save_states(orig_ts, orig_trajs, samp_ts, samp_trajs)\n",
    "                    print('Stored ckpt at {}'.format(ckpt_path))\n",
    "\n",
    "        print('Training complete after {} iters.'.format(itr))\n",
    "\n",
    "        if args.visualize:\n",
    "            # sample from trajectorys' approx. posterior\n",
    "            h = rec.initHidden()\n",
    "            for t in reversed(range(samp_trajs.shape[1])):\n",
    "                obs = samp_trajs[:, t, :]\n",
    "                out, h = rec(obs, h)\n",
    "            qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]\n",
    "            epsilon = tf.convert_to_tensor(np.random.randn(*qz0_mean.shape.as_list()), dtype=tf.float64)\n",
    "            z0 = epsilon * tf.exp(.5 * qz0_logvar) + qz0_mean\n",
    "            orig_ts = tf.convert_to_tensor(orig_ts, dtype=tf.float32)\n",
    "\n",
    "            # take first trajectory for visualization\n",
    "            z0 = z0[0:1]\n",
    "\n",
    "            ts_pos = np.linspace(0., 2. * np.pi, num=2000)\n",
    "            ts_neg = np.linspace(-np.pi, 0., num=2000)[::-1].copy()\n",
    "            ts_pos = tf.convert_to_tensor(ts_pos, dtype=tf.float32)\n",
    "            ts_neg = tf.convert_to_tensor(ts_neg, dtype=tf.float32)\n",
    "\n",
    "            zs_pos = odeint(func, z0, ts_pos)\n",
    "            zs_neg = odeint(func, z0, ts_neg)\n",
    "\n",
    "            xs_pos = dec(zs_pos)\n",
    "            xs_neg = tf.reverse(dec(zs_neg), axis=[0])\n",
    "\n",
    "            xs_pos = xs_pos.numpy().squeeze(1)\n",
    "            xs_neg = xs_neg.numpy().squeeze(1)\n",
    "            orig_traj = orig_trajs[0].numpy()\n",
    "            samp_traj = samp_trajs[0].numpy()\n",
    "\n",
    "            # xs_neg = np.clip(xs_neg, xs_pos.min(), xs_pos.max())\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(orig_traj[:, 0], orig_traj[:, 1],\n",
    "                     'g', label='true trajectory')\n",
    "            plt.plot(xs_pos[:, 0], xs_pos[:, 1], 'r',\n",
    "                     label='learned trajectory (t>0)')\n",
    "            plt.plot(xs_neg[:, 0], xs_neg[:, 1], 'c',\n",
    "                     label='learned trajectory (t<0)')\n",
    "            plt.scatter(samp_traj[:, 0], samp_traj[\n",
    "                        :, 1], label='sampled data', s=3)\n",
    "            plt.legend()\n",
    "            plt.savefig('./vis.png', dpi=500)\n",
    "            print('Saved visualization figure at {}'.format('./vis.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdiffeq",
   "language": "python",
   "name": "tfdiffeq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
